{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOeVXjm8xElo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "print(torch.__version__)\n",
        "\n",
        "# Install required packages.\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWhypf-cvC-A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "import networkx as nx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viFFMSzG4tVv"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12K9VTB2w8Yd"
      },
      "outputs": [],
      "source": [
        "dataset = MovieLens(os.getcwd(), model_name='all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XsAGLNhxew5"
      },
      "outputs": [],
      "source": [
        "data = dataset[0]\n",
        "\n",
        "# Add one-hot encoded vectors to identify users\n",
        "data['user'].x = torch.eye(data['user'].num_nodes)\n",
        "del data['user'].num_nodes\n",
        "data['movie'].node_id = torch.arange(9742)\n",
        "\n",
        "data = T.ToUndirected()(data)\n",
        "del data['movie', 'rev_rates', 'user'].edge_label  # Reverse labels are not needed\n",
        "\n",
        "print(data['user', 'rates', 'movie'].edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to permutate the data with a random permutation matrix\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "permutation = False\n",
        "\n",
        "if permutation:\n",
        "\n",
        "    user_permutation = np.eye(610)\n",
        "    movie_permutation = np.eye(9742)\n",
        "\n",
        "    user_permutation = np.random.permutation(user_permutation)\n",
        "    movie_permutation = np.random.permutation(movie_permutation)\n",
        "\n",
        "    user_origin = np.argmax(user_permutation, axis=1)\n",
        "    movie_origin = np.argmax(movie_permutation, axis=1)\n",
        "\n",
        "    user_permutation_mapping = {}\n",
        "    for i, s in enumerate(user_origin):\n",
        "        user_permutation_mapping[s] = i\n",
        "\n",
        "    movie_permutation_mapping = {}\n",
        "    for i, s in enumerate(movie_origin):\n",
        "        movie_permutation_mapping[s] = i\n",
        "\n",
        "    for i in range(100836):\n",
        "        o = data['user', 'rates', 'movie'].edge_index[0][i]\n",
        "        data['user', 'rates', 'movie'].edge_index[0][i] = user_permutation_mapping[int(o.numpy())]\n",
        "\n",
        "        o = data['user', 'rates', 'movie'].edge_index[1][i]\n",
        "        data['user', 'rates', 'movie'].edge_index[1][i] = movie_permutation_mapping[int(o.numpy())]\n",
        "\n",
        "        o = data['movie', 'rev_rates', 'user'].edge_index[0][i]\n",
        "        data['movie', 'rev_rates', 'user'].edge_index[0][i] = movie_permutation_mapping[int(o.numpy())]\n",
        "\n",
        "        o = data['movie', 'rev_rates', 'user'].edge_index[1][i]\n",
        "        data['movie', 'rev_rates', 'user'].edge_index[1][i] = user_permutation_mapping[int(o.numpy())]\n",
        "\n",
        "print(data['user', 'rates', 'movie'].edge_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QJ8tCRXeWAk",
        "outputId": "679bd2d3-78fd-4273-caf1-e462a68c76de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 434,  434,  434,  ...,  388,  388,  388],\n",
            "        [ 556, 8763, 9587,  ..., 2138, 3439, 8182]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.to(device)"
      ],
      "metadata": {
        "id": "3XQFR1Wzj-cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaHvewESzogf",
        "outputId": "032629c2-12e5-4078-d7a0-5c2c3dfb5a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  \u001b[1mmovie\u001b[0m={\n",
            "    x=[9742, 404],\n",
            "    node_id=[9742]\n",
            "  },\n",
            "  \u001b[1muser\u001b[0m={ x=[610, 610] },\n",
            "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
            "    edge_index=[2, 100836],\n",
            "    edge_label=[100836]\n",
            "  },\n",
            "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 100836] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGZQQkpL5KQP",
        "outputId": "93c81487-39f6-4d37-b0f4-97f64c2de3d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 1, 2, 3, 4, 5], device='cuda:0'), tensor([ 1370,  4602, 13101, 33183, 35369, 13211], device='cuda:0'))\n",
            "(tensor([0, 1, 2, 3, 4, 5], device='cuda:0'), tensor([ 285,  940, 2626, 6695, 6997, 2624], device='cuda:0'))\n",
            "HeteroData(\n",
            "  \u001b[1mmovie\u001b[0m={\n",
            "    x=[9742, 404],\n",
            "    node_id=[9742]\n",
            "  },\n",
            "  \u001b[1muser\u001b[0m={ x=[610, 610] },\n",
            "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
            "    edge_index=[2, 60502],\n",
            "    edge_label=[60502],\n",
            "    edge_label_index=[2, 60502]\n",
            "  },\n",
            "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 60502] }\n",
            ")\n",
            "HeteroData(\n",
            "  \u001b[1mmovie\u001b[0m={\n",
            "    x=[9742, 404],\n",
            "    node_id=[9742]\n",
            "  },\n",
            "  \u001b[1muser\u001b[0m={ x=[610, 610] },\n",
            "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
            "    edge_index=[2, 80669],\n",
            "    edge_label=[20167],\n",
            "    edge_label_index=[2, 20167]\n",
            "  },\n",
            "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 80669] }\n",
            ")\n",
            "HeteroData(\n",
            "  \u001b[1mmovie\u001b[0m={\n",
            "    x=[9742, 404],\n",
            "    node_id=[9742]\n",
            "  },\n",
            "  \u001b[1muser\u001b[0m={ x=[610, 610] },\n",
            "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
            "    edge_index=[2, 60502],\n",
            "    edge_label=[20167],\n",
            "    edge_label_index=[2, 20167]\n",
            "  },\n",
            "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 60502] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.2,\n",
        "    num_test=0.2,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('user', 'rates', 'movie')],\n",
        "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
        "    is_undirected=True,\n",
        "    key=\"edge_label\"\n",
        ")(data)\n",
        "\n",
        "print(data['user', 'rates', 'movie'].edge_label.unique(return_counts=True))\n",
        "\n",
        "print(test_data['user', 'rates', 'movie'].edge_label.unique(return_counts=True))\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)\n",
        "print(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bVHVYVHBpjB"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero, GATConv, SAGEConv\n",
        "from torch.nn import Linear, Dropout\n",
        "from torch_geometric.nn.aggr import MultiAggregation, MaxAggregation, MinAggregation, MeanAggregation, SumAggregation, StdAggregation\n",
        "\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dimension):\n",
        "        super().__init__()\n",
        "\n",
        "        mode_kwargs = {\n",
        "            \"in_channels\": -1,\n",
        "            \"out_channels\": hidden_dimension,\n",
        "            \"num_heads\": 1,\n",
        "        }\n",
        "\n",
        "        # Different methods of combining the aggregators\n",
        "\n",
        "        # self.conv1 = SAGEConv((-1, -1), hidden_dimension, aggr='add', normalize=True)\n",
        "        # self.conv2 = SAGEConv((-1, -1), hidden_dimension, aggr='add', normalize=True)\n",
        "        # self.conv3 = SAGEConv((-1, -1), hidden_dimension, aggr='add', normalize=True)\n",
        "\n",
        "        # self.conv1 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), SumAggregation()]), normalize=True)\n",
        "        # self.conv2 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), SumAggregation()]), normalize=True)\n",
        "        # self.conv3 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), SumAggregation()]), normalize=True)\n",
        "\n",
        "        # self.conv1 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), MinAggregation(), MaxAggregation(), StdAggregation()]))\n",
        "        # self.conv2 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), MinAggregation(), MaxAggregation(), StdAggregation()]))\n",
        "        # self.conv3 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), MinAggregation(), MaxAggregation(), StdAggregation()]))\n",
        "\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), StdAggregation()], mode='attn', mode_kwargs=mode_kwargs))\n",
        "        self.conv2 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), StdAggregation()], mode='attn', mode_kwargs=mode_kwargs))\n",
        "        self.conv3 = SAGEConv((-1, -1), hidden_dimension, aggr=MultiAggregation(aggrs=[MeanAggregation(), StdAggregation()], mode='attn', mode_kwargs=mode_kwargs))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RatingClassifier(torch.nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, hidden_dimension):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear1 = Linear(2 * hidden_dimension, 64)\n",
        "        self.linear2 = Linear(64, 1)\n",
        "        self.dropout1 = Dropout(p=0.3)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_label_index):\n",
        "\n",
        "        row_indices = edge_label_index[0]\n",
        "        column_indices = edge_label_index[1]\n",
        "\n",
        "        concat_features = torch.cat([x['user'][row_indices], x['movie'][column_indices]], dim=-1)\n",
        "\n",
        "        concat_features = self.dropout1(self.linear1(concat_features).relu())\n",
        "        concat_features = self.linear2(concat_features)\n",
        "\n",
        "        return concat_features.view(-1)\n",
        "\n",
        "\n",
        "class RecommenderGNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_dimensions):\n",
        "        super().__init__()\n",
        "\n",
        "        self.movie_embedding = torch.nn.Linear(404, hidden_dimensions)\n",
        "        self.user_embedding = torch.nn.Linear(610, hidden_dimensions)\n",
        "        self.movie_id_embedding = torch.nn.Embedding(data['movie'].num_nodes, hidden_dimensions)\n",
        "\n",
        "        self.encoder = Encoder(hidden_dimensions)\n",
        "        self.encoder = to_hetero(self.encoder, metadata=data.metadata())\n",
        "\n",
        "        self.classifier = RatingClassifier(hidden_dimensions)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        user_embedding = self.user_embedding(data['user'].x)\n",
        "        movie_embedding = self.movie_embedding(data['movie'].x)\n",
        "        movie_id_embedding = self.movie_id_embedding(data['movie'].node_id)\n",
        "\n",
        "        x_dict = {\n",
        "          \"user\": user_embedding,\n",
        "          \"movie\": movie_embedding + movie_id_embedding\n",
        "        } \n",
        "\n",
        "        x_dict = self.encoder(x_dict, data.edge_index_dict)\n",
        "\n",
        "        pred = self.classifier(x_dict, data[\"user\", \"rates\", \"movie\"].edge_label_index,)\n",
        "\n",
        "        return pred\n",
        "\n",
        "model = RecommenderGNN(16).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    model(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, loss_func, optimizer):\n",
        "    data = data.to(device)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    prediction = model(data)\n",
        "    target = data['user', 'movie'].edge_label.float()\n",
        "    loss = loss_func(prediction, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.sqrt())"
      ],
      "metadata": {
        "id": "KGlzUMcRYDsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data = data.to(device)\n",
        "        prediction = model(data)\n",
        "        prediction = prediction.clamp(min=0, max=5)\n",
        "        target = data['user', 'movie'].edge_label.float()\n",
        "        rmse = torch.nn.functional.mse_loss(prediction, target).sqrt()\n",
        "        return rmse\n"
      ],
      "metadata": {
        "id": "X9UJWlbvZzBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for D in [16, 32, 64]:\n",
        "\n",
        "    model = RecommenderGNN(D)\n",
        "    model.to(device)\n",
        "\n",
        "    loss_func = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    with torch.no_grad():  # lazy initialization of dimensions\n",
        "        model(train_data)\n",
        "\n",
        "    min_train_loss = 100\n",
        "    min_val_loss = 100\n",
        "    min_test_loss = 100\n",
        "\n",
        "    print()\n",
        "    print(f\"Dimension {D}\")\n",
        "\n",
        "\n",
        "    for epoch in range(1, 401):\n",
        "\n",
        "        train_loss = train(model, train_data, loss_func, optimizer)\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        test_loss = evaluate(model, test_data)\n",
        "\n",
        "        if val_loss < min_val_loss:\n",
        "            min_train_loss = min(min_train_loss, train_loss)\n",
        "            min_test_loss = min(min_test_loss, test_loss)\n",
        "            min_val_loss = min(min_val_loss, val_loss)\n",
        "\n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch}  Train: {min_train_loss:.3f}   Val: {min_val_loss:.3f}   Test: {min_test_loss:.3f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScyjOIvEXh_o",
        "outputId": "d51ee1bc-4d94-4fcb-fcb4-cbc002c38244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension 16\n",
            "Epoch 20  Train: 1.524   Val: 1.315   Test: 1.307\n",
            "Epoch 40  Train: 1.262   Val: 1.093   Test: 1.103\n",
            "Epoch 60  Train: 1.208   Val: 1.085   Test: 1.094\n",
            "Epoch 80  Train: 1.190   Val: 1.081   Test: 1.089\n",
            "Epoch 100  Train: 1.175   Val: 1.079   Test: 1.086\n",
            "Epoch 120  Train: 1.157   Val: 1.070   Test: 1.077\n",
            "Epoch 140  Train: 1.139   Val: 1.058   Test: 1.065\n",
            "Epoch 160  Train: 1.119   Val: 1.042   Test: 1.049\n",
            "Epoch 180  Train: 1.093   Val: 1.022   Test: 1.030\n",
            "Epoch 200  Train: 1.071   Val: 1.004   Test: 1.011\n",
            "Epoch 220  Train: 1.049   Val: 0.992   Test: 1.000\n",
            "Epoch 240  Train: 1.040   Val: 0.988   Test: 0.995\n",
            "Epoch 260  Train: 1.032   Val: 0.986   Test: 0.993\n",
            "Epoch 280  Train: 1.029   Val: 0.986   Test: 0.993\n",
            "Epoch 300  Train: 1.021   Val: 0.986   Test: 0.992\n",
            "Epoch 320  Train: 1.014   Val: 0.984   Test: 0.990\n",
            "Epoch 340  Train: 1.008   Val: 0.981   Test: 0.986\n",
            "Epoch 360  Train: 0.998   Val: 0.978   Test: 0.983\n",
            "Epoch 380  Train: 0.988   Val: 0.975   Test: 0.979\n",
            "Epoch 400  Train: 0.984   Val: 0.973   Test: 0.977\n",
            "\n",
            "Dimension 32\n",
            "Epoch 20  Train: 1.312   Val: 1.099   Test: 1.104\n",
            "Epoch 40  Train: 1.217   Val: 1.085   Test: 1.094\n",
            "Epoch 60  Train: 1.217   Val: 1.082   Test: 1.092\n",
            "Epoch 80  Train: 1.199   Val: 1.077   Test: 1.087\n",
            "Epoch 100  Train: 1.171   Val: 1.068   Test: 1.076\n",
            "Epoch 120  Train: 1.148   Val: 1.050   Test: 1.059\n",
            "Epoch 140  Train: 1.113   Val: 1.024   Test: 1.033\n",
            "Epoch 160  Train: 1.079   Val: 0.994   Test: 1.004\n",
            "Epoch 180  Train: 1.059   Val: 0.980   Test: 0.990\n",
            "Epoch 200  Train: 1.052   Val: 0.975   Test: 0.986\n",
            "Epoch 220  Train: 1.046   Val: 0.973   Test: 0.984\n",
            "Epoch 240  Train: 1.040   Val: 0.972   Test: 0.982\n",
            "Epoch 260  Train: 1.034   Val: 0.971   Test: 0.981\n",
            "Epoch 280  Train: 1.031   Val: 0.968   Test: 0.977\n",
            "Epoch 300  Train: 1.019   Val: 0.964   Test: 0.973\n",
            "Epoch 320  Train: 1.008   Val: 0.959   Test: 0.967\n",
            "Epoch 340  Train: 0.999   Val: 0.954   Test: 0.963\n",
            "Epoch 360  Train: 0.989   Val: 0.952   Test: 0.960\n",
            "Epoch 380  Train: 0.982   Val: 0.951   Test: 0.959\n",
            "Epoch 400  Train: 0.977   Val: 0.951   Test: 0.959\n",
            "\n",
            "Dimension 64\n",
            "Epoch 20  Train: 1.358   Val: 1.104   Test: 1.107\n",
            "Epoch 40  Train: 1.216   Val: 1.095   Test: 1.102\n",
            "Epoch 60  Train: 1.176   Val: 1.083   Test: 1.089\n",
            "Epoch 80  Train: 1.157   Val: 1.076   Test: 1.081\n",
            "Epoch 100  Train: 1.115   Val: 1.045   Test: 1.050\n",
            "Epoch 120  Train: 1.062   Val: 1.008   Test: 1.011\n",
            "Epoch 140  Train: 1.042   Val: 0.988   Test: 0.993\n",
            "Epoch 160  Train: 1.030   Val: 0.981   Test: 0.988\n",
            "Epoch 180  Train: 1.020   Val: 0.976   Test: 0.983\n",
            "Epoch 200  Train: 1.004   Val: 0.969   Test: 0.975\n",
            "Epoch 220  Train: 0.993   Val: 0.966   Test: 0.971\n",
            "Epoch 240  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 260  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 280  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 300  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 320  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 340  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 360  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 380  Train: 0.979   Val: 0.964   Test: 0.968\n",
            "Epoch 400  Train: 0.979   Val: 0.964   Test: 0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GLxaAk9CBaxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}